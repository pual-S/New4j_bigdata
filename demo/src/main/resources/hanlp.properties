#Windows用户请注意，路径分隔符统一使用/
root=/opt/HanLP
#root=D:/BigData_project/demo/src/main/resources/HanLP
#核心词典路径
CoreDictionaryPath=data/dictionary/CoreNatureDictionary.txt
#2元语法词典路径
BiGramDictionaryPath=data/dictionary/CoreNatureDictionary.ngram.txt
#停用词词典路径
CoreStopWordDictionaryPath=data/dictionary/stopwords.txt
#同义词词典路径
CoreSynonymDictionaryDictionaryPath=data/dictionary/synonym/CoreSynonym.txt
#人名词典路径
PersonDictionaryPath=data/dictionary/person/nr.txt
#人名词典转移矩阵路径
PersonDictionaryTrPath=data/dictionary/person/nr.tr.txt
#繁简词典根目录
tcDictionaryRoot=data/dictionary/tc
#自定义词典路径，用;隔开多个自定义词典，空格开头表示在同一个目录，使用“文件名 词性”形式则表示这个词典的词性默认是该词性。优先级递减。
#另外data/dictionary/custom/CustomDictionary.txt是个高质量的词库，请不要删除。所有词典统一使用【UTF-8】编码。
#注意，每次更新自己定义的新词典myDict.txt的内容时,要删除同目录下的词典缓存文件CustomDictionary.txt.bin
CustomDictionaryPath=data/dictionary/custom/CustomDictionary.txt; Symptoms.txt sym; disease.txt dz; 向量词典.txt nm; 全国地名大全.txt ns; 人名词典.txt; 机构名词典.txt; 上海地名.txt ns;

#CRF分词模型路径
CRFSegmentModelPath=data/model/segment/CRFSegmentModel.txt
#HMM分词模型
HMMSegmentModelPath=data/model/segment/HMMSegmentModel.bin
#分词结果是否展示词性
ShowTermNature=true